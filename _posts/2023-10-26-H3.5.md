---
title: Statistic H_3.5
date: 2023-10-26 18:18:11 +/-0000
categories: [learning]
math: true
---


# Practical part 

Revise and optimize you previous programs to compute the joint distribution of any number of 2,3, ...k, continuous quantitative variables
where, for each variable, the user can specify the number of subdivisions ("class intervals") of a range containing the observed values.

Revise also your previous homework taking into account that qualitative variables can be ordered and therefore the order needs to be preserved.

For quantitative variables, include the possibility to specify class intervals too.

# Implementation

The prevous version of the program was integrated to support the joint of K continuous variables, 

{% include embed/youtube.html id='DPkYLyuy6Us' %}
                                  
The text field enable the user to choose how many intervals he wants for each variable, the first number refers to the first (not temporarly) selected variable in the checkbox below

![Desktop View](/assets/statiistics/H3.5/n1.png){: w="500"}



## Optional
Create a some visual representation of the distribution. Use creatively your fantasy and skills (you may invent new representations, if you like).


# Theory 

Research

(Revise and improve your simulations in homework 3, where necessary.)
Search on the web about the Law of large numbers LLN and compare it with Part b of your homework 3 and express in your own words whether your simulation is somehow related with this theorem, and why.
Search on the web about the Central Limit Theorem CLT and compare it with Part a of your homework 3 and say in your own words whether your simulation is somehow related with this theorem, and why.
Based on the CLT, how could you modify ("normalize") the "security score" to obtain an asymptotic convergence to a proper distribution?

## LLN (tanti sistemi anchi pochi sample = circa stesso risultato)
The law of large numbers states that even random events with a large number of trials may return stable long-term results. Note that the theorem deals only with a large number of trials while the average of the results of the experiment repeated a small number of times might be substantially different from the expected value. <br>

A Law of Large Numbers (LLN) is a proposition that provides a set of sufficient conditions for the convergence of the sample mean to a constant.

Let {Xn} be a sequence of random variables.

Let Xn be the sample mean of the first n terms of the sequence:

$$
  \overline{X_n} =  \frac{1}{n}\sum_{i=1}^n X_i  
$$
<br>
A Law of Large Numbers (LLN) states some conditions that are sufficient to guarantee the convergence of Xn to a constant, as the sample size n increases.

Typically, the constant is the expected value of the distribution from which the sample has been drawn:

![g1](/assets/statiistics/H3.5/G1.gif)
_demo_

Typically, all the random variables in the sequence { $X_n$ } have the same expected value  $E\left[ X_n \right] = \mu$ . In this case, the constant to which the sample mean converges is mu (which is called population mean).

#Example of Law of Large Numbers

The simplest example of the law of large numbers is rolling the dice. The dice involves six different events with equal probabilities. The expected value of the dice events is:

$$
EV=\frac{1+2+3+4+5+6}{6}=3.5
$$

 

If we roll the dice only three times, the average of the obtained results may be far from the expected value. Letâ€™s say you rolled the dice three times and the outcomes were 6, 6, 3. The average of the results is 5. According to the law of the large numbers, if we roll the dice a large number of times, the average result will be closer to the expected value of 3.5.

## COMPARE WITH PART B (modifica)

The part B of the previous homework asked to "simulate the cumulated frequency, say f, of penetration. Do the same with the relative..." , there the probability of fail/success was fixed and chosen by the user so the shape that will appear is not related to the LLN (infact the result is not a uniform distributon) but will be a bell curve.

## CLT

The Central Limit Theorem (CLT) is a statistical concept that states that the sample mean distribution of a random variable will assume a near-normal or normal distribution if the sample size is large enough. In simple terms, the theorem states that the sampling distribution of the mean approaches a normal distribution as the size of the sample increases, regardless of the shape of the original population distribution. <br>


![g2](/assets/statiistics/h3/normal.png)
_demo_

As the user increases the number of samples to 30, 40, 50, etc., the graph of the sample means will move towards a normal distribution. The sample size must be 30 or higher for the central limit theorem to hold.

One of the most important components of the theorem is that the **mean of the sample will be the mean of the entire population**. If you calculate the mean of multiple samples of the population, add them up, and find their average, the result will be the estimate of the population mean. <br>

# How Does the Central Limit Theorem Work? 
The central limit theorem forms the basis of the probability distribution. It makes it easy to understand how population estimates behave when subjected to repeated sampling. When plotted on a graph, the theorem shows the shape of the distribution formed by means of repeated population samples.

As the sample sizes get bigger, the distribution of the means from the repeated samples tends to normalize and resemble a normal distribution. The result remains the same regardless of what the original shape of the distribution was. It can be illustrated in the figure below:

![g2](/assets/statiistics/H3.5/bell.png)
_demo_

From the figure above, we can deduce that despite the fact that the original shape of the distribution was uniform, it tends towards a normal distribution as the value of n (sample size) increases.
Apart from showing the shape that the sample means will take, the central limit theorem also gives an overview of the mean and variance of the distribution. The sample mean of the distribution is the actual population mean from which the samples were taken.
The variance of the sample distribution, on the other hand, is the variance of the population divided by n. Therefore, the larger the sample size of the distribution, the smaller the variance of the sample mean

# Compare with part A
The part A's instogram will plot the number of successfull attacks of each system analized, however the CLT is not directly visible from the charts. To "obtain an asymptotic convergence to a proper distribution" the instogram shoul display fro each system the **average** of successfull attacks (num_breaches/tot_attacks) and also use a large number of samples






es:
- **Simple random sampling** callsenerator 

- **Systematic sampling** calls for at a speci


> ref
> https://www.statlect.com/asymptotic-theory/law-of-large-numbers
> https://corporatefinanceinstitute.com/resources/data-science/central-limit-theorem/

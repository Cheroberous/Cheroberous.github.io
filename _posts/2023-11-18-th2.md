---
title: Statistic th2
date: 2023-11-18 11:12:11 +/-0000
categories: [learning]
math: true
---

## CLT

The Central Limit Theorem (CLT) is a statistical concept that states that the sample mean distribution of a random variable will assume a near-normal or normal distribution if the sample size is large enough. In simple terms, the theorem states that the sampling distribution of the mean approaches a normal distribution as the size of the sample increases (as also shown in the "simulation" part in the th1), regardless of the shape of the original population distribution. <br>


![g2](/assets/statiistics/h3/normal.png){: w="400", : h="300"}
_demo_

As the user increases the number of samples to 30, 40, 50, etc., the graph of the sample means will move towards a normal distribution. The sample size must be 30 or higher for the central limit theorem to hold. <br>
One of the most important components of the theorem is that the **mean of the sample will be the mean of the entire population**. If you calculate the mean of multiple samples of the population, add them up, and find their average, the result will be the estimate of the population mean. <br>

# How Does the Central Limit Theorem Work? 
The central limit theorem forms the basis of the probability distribution. It makes it easy to understand how population estimates behave when subjected to repeated sampling. When plotted on a graph, the theorem shows the shape of the distribution formed by means of repeated population samples.

As the sample sizes get bigger, the distribution of the means from the repeated samples tends to normalize and resemble a normal distribution. The result remains the same regardless of what the original shape of the distribution was. It can be illustrated in the figure below:

![g2](/assets/statiistics/H3.5/bell.png){: h="250"}
_demo_

From the figure above, we can deduce that despite the fact that the original shape of the distribution was uniform, it tends towards a normal distribution as the value of n (sample size) increases. <br>
Apart from showing the shape that the sample means will take, the central limit theorem also gives an overview of the mean and variance of the distribution. <br>
The sample mean of the distribution is the actual population mean from which the samples were taken. <br>
The variance of the sample distribution, on the other hand, is the variance of the population divided by n. Therefore, the larger the sample size of the distribution, the smaller the variance of the sample mean

## Componens of the CLT

As the sample size increases, the sampling distribution of the mean, X-bar, can be approximated by a normal distribution with mean µ and standard deviation σ/√n where:
+ µ is the population mean
+ σ is the population standard deviation
+ n is the sample size

Suppose we draw a random sample of size n (x1, x2, x3, … xn — 1, xn) from a population random variable that is distributed with mean µ and standard deviation σ.

Do this repeatedly, drawing many samples from the population, and then calculate the $\overall X $ of each sample. <br>

We will treat the $ \overal X $ values as another distribution, which we will call the sampling distribution of the mean. <br>

Given a distribution with a mean μ and variance $ σ^2 $, the sampling distribution of the mean approaches a normal distribution with a mean (μ) and a variance $\frac{σ^2}{n} $ as n, the sample size, increases and the amazing and very interesting intuitive thing about the central limit theorem is that no matter what the shape of the original (parent) distribution, the sampling distribution of the mean approaches a normal distribution.

A normal distribution is approached very quickly as n increases (note that n is the sample size for each mean and not the number of samples).

Remember, in a sampling distribution of the mean the number of samples is assumed to be infinite.

To wrap up, there are three different components of the central limit theorem:
+ Successive sampling from a population
+ Increasing sample size
+ Population distribution







Ref.
>https://builtin.com/data-science/understanding-central-limit-theorem
>https://corporatefinanceinstitute.com/resources/data-science/central-limit-theorem/ <br>
